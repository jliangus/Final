---
title: "Wine Review Analysis"
author: "Jackie Liang"
date: "December 17, 2018"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(dplyr)
library(ggplot2)
library(data.table)
library(wordcloud)
library(readr)
```
# Wine Review Text Analysis
## Final Project

This dataset is publicly available from Kaggle. 

A collection of 130 thousand wine reviews: with information on the taster, the price, the score, grape variety and origin, and the text of the review itself which is of interest in this project. 


#Data Processing 
Creating a constructor and a function that creates a corpus from the wine reviews. 
```{r, cache=TRUE, message=FALSE}
setwd("~/Data Science Programming/Final Project")
WineDataset <- function(){
  df <- read_csv("winemag-data-130k-v2.csv")
  return(df)
}
  
wine <- WineDataset()

create_corpus<-function(text_vector){
  text_corpus<-Corpus(VectorSource(text_vector),readerControl=list(language="english"))%>%
    tm_map(stripWhitespace)%>%
    tm_map(tolower)%>%
    tm_map(removeWords,c(stopwords("english"),"wine"))%>%
    tm_map(stemDocument)
  return(text_corpus)
}

corpus <- create_corpus(wine$description)
```

#Brief Exploration of the Data

```{r, cache=TRUE, warning=FALSE}
plot <- ggplot()
plot2 <- plot + geom_histogram(mapping = aes(x=points), data = wine, binwidth = 1, color= 'white') + 
  coord_cartesian(xlim = c(75, 100)) +
  labs(title ="Review Distribution", x = "Review Score", y = "Number of Reviews") +
  scale_x_continuous(breaks=seq(75,100, by = 1))

plot2

plot3 <- plot + geom_histogram(mapping = aes(x=price), data = wine, binwidth = 5, color= 'white') + 
  coord_cartesian(xlim = c(0, 150)) +
  labs(title ="Wines under $150", x = "Price", y = "Count")

plot3

```
#What Are The Words Most Associated With Wines? 
Function that generates wordclouds of frequent words associated with wine.
```{r, cache=TRUE, warning=FALSE}
setwd("~/Data Science Programming/Final Project")
create_wordcloud <- function(){
  wine <- WineDataset()
  wineCorpus <- Corpus(VectorSource(wine$description))
  wineCorpus <- tm_map(wineCorpus, PlainTextDocument)
  wineCorpus <- tm_map(wineCorpus, removePunctuation)
  wineCorpus <- tm_map(wineCorpus, removeWords, stopwords('english'))
  wineCorpus <- tm_map(wineCorpus, stemDocument)
  wineCorpus <- Corpus(VectorSource(wineCorpus))
  print(wineCorpus)
  wineCorpus <- tm_map(wineCorpus, removeWords, c('the', 'this', 'wine', stopwords('english')))
  myDTM = TermDocumentMatrix(wineCorpus, control = list(minWordLength = 1))
  m = as.matrix(myDTM)
  v = sort(rowSums(m), decreasing = TRUE)
  cloud <- wordcloud(names(v), v, main = "All Wines", max.words = 100, colors=brewer.pal(8, "Dark2")) 
  return(cloud)
}

create_wordcloud()
```
#Are There Different Words by Variety?
Wordcloud function, input any variety known variety (capable of 708 varieties) and see the words associated with that type of wine. 
```{r, cache=TRUE, warning=FALSE}
setwd("~/Data Science Programming/Final Project")
wordcloud_by_variety <- function(df, variety){
  toprated <- subset(df, variety == variety)
  wineCorpus1 <- Corpus(VectorSource(toprated$description))
  wineCorpus1 <- tm_map(wineCorpus1, PlainTextDocument)
  wineCorpus1 <- tm_map(wineCorpus1, removePunctuation)
  wineCorpus1 <- tm_map(wineCorpus1, removeWords, stopwords('english'))
  wineCorpus1 <- tm_map(wineCorpus1, stemDocument)
  wineCorpus1 <- Corpus(VectorSource(wineCorpus1))
  wineCorpus1 <- tm_map(wineCorpus1, removeWords, c('the', 'this', 'wine', stopwords('english')))
  myDTM1 = TermDocumentMatrix(wineCorpus1, control = list(minWordLength = 1))
  m1 = as.matrix(myDTM1)
  v1 = sort(rowSums(m1), decreasing = TRUE)
  cloud <- wordcloud(names(v1), v1, max.words = 100, colors=brewer.pal(8, "Dark2"), main = "Wine Description for Varieties")
  return(cloud)
}
#Red variety
wordcloud_by_variety(wine, "Rosso")
#White variety
wordcloud_by_variety(wine, "Prosecco")
```

```{r, cache=TRUE, warning=FALSE}
setwd("~/Data Science Programming/Final Project")
Model <- function(corpus){
  dtm<-DocumentTermMatrix(corpus)
  sparse<-removeSparseTerms(dtm, sparse = 0.6)
  term_freq<-findFreqTerms(dtm,1000)
  dtm1<-as.matrix(sparse)
  
  dtm<-TermDocumentMatrix(corpus,control=
                            list(dictionary=term_freq,removeNumbers=TRUE,
                                 stopwords=TRUE,
                                 weighting=weightTfIdf))
  dtm_matrix<-as.matrix(dtm)
  
  winecharacter<-t(dtm_matrix)
  colnames(winecharacter) <- names(dtm_matrix[,1])
  
  winecharacter<-data.frame(winecharacter,country=wine$country,
                            designation=wine$designation,
                            points=wine$points,
                            price=wine$price)
  
  winecharacter1<-data.frame(winecharacter[,1:200],points=winecharacter$points)
  model<-lm(points~.,winecharacter1)
  return(model)
}

model <- Model(corpus)
model
```

Conclusion
1. As a whole, wine reviews are roughly normally distributed around a mean of 89. Most wines reviewed are around the $20 mark. 

2. From the term frequencies, typical words used to describe wines are fruit: for example, cherry, plum, or raspberry. This varies slightly depending on the variety of wine, especially if one is comparing a red to a white wine. 

3. Using a linear regression model of wine review score on term frequency, the model estimates that reviews describing wines as "elegant" or "rich" score 2.54 and 4.13 points higher. While the model used a very naive regression model, it is still interesting to see what flavor notes are appreciated in reviews. 

some confounding trends are that these words are aggregated without controlling for the type of wine -- wherein a good red wine can have a lot of tannin, white wines should not have any and thus the term tannin is underestimated. The intercept for the model is very high as well since it is a naive model with only one variable, therefore many words seems to be underestimated. 

